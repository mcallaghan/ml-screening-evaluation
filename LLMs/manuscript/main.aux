\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{lefebvre_chapter_2023}
\HyPL@Entry{0<</S/D>>}
\citation{omara-eves_using_2015}
\citation{cohen_reducing_2006}
\citation{lefebvre_chapter_2023}
\citation{wang_zero-shot_2024}
\citation{SneydS19,callaghan_statistical_2020,lewis_confidence_2023}
\citation{wang_zero-shot_2024}
\citation{de_bruin_synergy_2023}
\citation{callaghan_statistical_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Rankings produced by LLM-assisted screening (coloured lines) and by active learning using a support vector machine. Left panel shows the recall achieved at different proportions of relevant documents screened. Right panel shows the distribution of ROC AUC scores for the support vector machine approach (boxplot) and for LLMs (coloured crosses)}}{5}{figure.1}\protected@file@percent }
\newlabel{fig:rankings}{{1}{5}{Rankings produced by LLM-assisted screening (coloured lines) and by active learning using a support vector machine. Left panel shows the recall achieved at different proportions of relevant documents screened. Right panel shows the distribution of ROC AUC scores for the support vector machine approach (boxplot) and for LLMs (coloured crosses)}{figure.1}{}}
\citation{callaghan_statistical_2020}
\citation{callaghan_statistical_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The distribution of ROC AUC scores across datasets. The results for the support vector machine (SVM) display the median score for each dataset.}}{6}{figure.2}\protected@file@percent }
\newlabel{fig:macro}{{2}{6}{The distribution of ROC AUC scores across datasets. The results for the support vector machine (SVM) display the median score for each dataset}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Recall achieved at the 1-confidence percentile across model runs. Values below the recall target are highlighted in bold.}}{7}{table.1}\protected@file@percent }
\newlabel{tab:recall}{{1}{7}{Recall achieved at the 1-confidence percentile across model runs. Values below the recall target are highlighted in bold}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Average proportional work savings across datasets for each combination of model recall target and confidence level. For the SVM column where there are multiple runs per dataset, we first calculate the median value for each dataset before aggregating across datasets.}}{8}{table.2}\protected@file@percent }
\newlabel{tab:wssp}{{2}{8}{Average proportional work savings across datasets for each combination of model recall target and confidence level. For the SVM column where there are multiple runs per dataset, we first calculate the median value for each dataset before aggregating across datasets}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Average proportional work savings across datasets for each combination of model recall target and confidence level. For the SVM column where there are multiple runs per dataset, we first calculate the median value for each dataset before aggregating across datasets.}}{8}{table.3}\protected@file@percent }
\newlabel{tab:wsst}{{3}{8}{Average proportional work savings across datasets for each combination of model recall target and confidence level. For the SVM column where there are multiple runs per dataset, we first calculate the median value for each dataset before aggregating across datasets}{table.3}{}}
\citation{callaghan_statistical_2020}
\bibstyle{unsrt}
\bibdata{../stopping-criteria}
\bibcite{lefebvre_chapter_2023}{{1}{}{{}}{{}}}
\bibcite{omara-eves_using_2015}{{2}{}{{}}{{}}}
\bibcite{cohen_reducing_2006}{{3}{}{{}}{{}}}
\bibcite{wang_zero-shot_2024}{{4}{}{{}}{{}}}
\bibcite{SneydS19}{{5}{}{{}}{{}}}
\bibcite{callaghan_statistical_2020}{{6}{}{{}}{{}}}
\bibcite{lewis_confidence_2023}{{7}{}{{}}{{}}}
\bibcite{de_bruin_synergy_2023}{{8}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{10}
